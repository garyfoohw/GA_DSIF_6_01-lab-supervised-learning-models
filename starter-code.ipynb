{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"401ksubs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>0</td>\n",
       "      <td>58.428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3413.8310</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271</th>\n",
       "      <td>0</td>\n",
       "      <td>24.546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>602.5061</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>0</td>\n",
       "      <td>38.550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>-13.600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1486.1020</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>0</td>\n",
       "      <td>34.410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>3.550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1184.0480</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9274</th>\n",
       "      <td>0</td>\n",
       "      <td>25.608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>655.7697</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9275 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0         0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1         1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2         0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3         0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4         0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "...     ...     ...   ...   ...  ...    ...      ...    ...   ...        ...   \n",
       "9270      0  58.428     1     0   33      4   -1.200      0     0  3413.8310   \n",
       "9271      0  24.546     0     1   37      3    2.000      0     0   602.5061   \n",
       "9272      0  38.550     1     0   33      3  -13.600      0     1  1486.1020   \n",
       "9273      0  34.410     1     0   57      3    3.550      0     0  1184.0480   \n",
       "9274      0  25.608     0     1   49      1    1.800      0     0   655.7697   \n",
       "\n",
       "      agesq  \n",
       "0      1600  \n",
       "1      1225  \n",
       "2      1936  \n",
       "3      1936  \n",
       "4      2809  \n",
       "...     ...  \n",
       "9270   1089  \n",
       "9271   1369  \n",
       "9272   1089  \n",
       "9273   3249  \n",
       "9274   2401  \n",
       "\n",
       "[9275 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#1) Whether employer offered a match  \n",
    "#2) Favours a tax break now, or later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is akin to racial profiling.  \n",
    "Ideally, race should have no bearing on a person's income and financial decisions, and hence should not be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>58.428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>3413.8310</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271</th>\n",
       "      <td>24.546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000</td>\n",
       "      <td>602.5061</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>38.550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>-13.600</td>\n",
       "      <td>1486.1020</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>34.410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>3.550</td>\n",
       "      <td>1184.0480</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9274</th>\n",
       "      <td>25.608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.800</td>\n",
       "      <td>655.7697</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9275 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         inc  marr  male  age  fsize   nettfa      incsq  agesq\n",
       "0     13.170     0     0   40      1    4.575   173.4489   1600\n",
       "1     61.230     0     1   35      1  154.000  3749.1130   1225\n",
       "2     12.858     1     0   44      2    0.000   165.3282   1936\n",
       "3     98.880     1     1   44      2   21.800  9777.2540   1936\n",
       "4     22.614     0     0   53      1   18.450   511.3930   2809\n",
       "...      ...   ...   ...  ...    ...      ...        ...    ...\n",
       "9270  58.428     1     0   33      4   -1.200  3413.8310   1089\n",
       "9271  24.546     0     1   37      3    2.000   602.5061   1369\n",
       "9272  38.550     1     0   33      3  -13.600  1486.1020   1089\n",
       "9273  34.410     1     0   57      3    3.550  1184.0480   3249\n",
       "9274  25.608     0     1   49      1    1.800   655.7697   2401\n",
       "\n",
       "[9275 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.drop(columns=['e401k','p401k','pira'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously `incsq` should not be used, because that a direct `sqrt()` of `incsq` gives the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`incsq` and `agesq` are engineed features.  \n",
    "This is becuase income and age may have polynomial relations with the other variables - one grow at a faster rate that the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`inc` should not say `inc^2`. It should just mention <i>income</i>.<br>\n",
    "Same goes for `age`, should not say `age^2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What do you mean by <i>modelling tactic</i>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1.drop(columns=['inc'])\n",
    "y=df1['inc']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_reg(regressor):\n",
    "    return Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('regressor',regressor)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors_name=['LinReg','KNN','DecTree','BaggedDecTrees','RandForest','Adaboost','SVR']\n",
    "regressors_instance=[LinearRegression(),KNeighborsRegressor(),DecisionTreeRegressor(),\n",
    "                    BaggingRegressor(),RandomForestRegressor(),AdaBoostRegressor(),SVR()]\n",
    "regressors_score=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(regressors_name)):\n",
    "    pipe=create_pipeline_reg(regressors_instance[i])\n",
    "    pipe.fit(X_train,y_train)\n",
    "    regressors_score.append(pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandForest</th>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggedDecTrees</th>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecTree</th>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>0.990326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.963919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinReg</th>\n",
       "      <td>0.905139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.903933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Accuracy score\n",
       "RandForest            0.999996\n",
       "BaggedDecTrees        0.999989\n",
       "DecTree               0.999985\n",
       "Adaboost              0.990326\n",
       "KNN                   0.963919\n",
       "LinReg                0.905139\n",
       "SVR                   0.903933"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_scores=pd.DataFrame([regressors_score],columns=regressors_name).T\n",
    "reg_scores.columns=['Accuracy score']\n",
    "reg_scores.sort_values(by=\"Accuracy score\",ascending=False,inplace=True)\n",
    "reg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears random forest does the best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Creation of a new population based on random sampling with replacement on the original population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A decision tree is just 1 tree. Susceptible to high bias.  \n",
    "A bagged decision trees uses bootstrapped populations on multiple trees, before aggregating the results.  \n",
    "A bagged decision tree reduces variance, but has higher bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bagged decision trees uses bootstrapped populations and aggregate the results.  \n",
    "Random forest adds a layer of complexity by randomly selecting (or dropping) some features in every split of the tree branch.  \n",
    "This prevents the trees from being overly reliant on one (or a few) features all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The avoidance of over-reliance on specific features allow a RF to generalise better.  \n",
    "This means a lower variance but higher bias.  \n",
    "As mentioned, a RF generalises better than a Bagged Decision Trees, hence it is more superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors_RMSE_train=[]\n",
    "regressors_RMSE_test=[]\n",
    "for i in range(len(regressors_name)):\n",
    "    pipe=create_pipeline(regressors_instance[i])\n",
    "    pipe.fit(X_train,y_train)\n",
    "    regressors_RMSE_train.append(mean_squared_error(y_train,pipe.predict(X_train),squared=False))\n",
    "    regressors_RMSE_test.append(mean_squared_error(y_test,pipe.predict(X_test),squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE train score</th>\n",
       "      <th>RMSE test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandForest</th>\n",
       "      <td>6.925209e-02</td>\n",
       "      <td>0.051365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecTree</th>\n",
       "      <td>5.872712e-16</td>\n",
       "      <td>0.088696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggedDecTrees</th>\n",
       "      <td>1.149761e-01</td>\n",
       "      <td>0.102959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>2.265848e+00</td>\n",
       "      <td>2.251459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>3.395318e+00</td>\n",
       "      <td>4.474329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinReg</th>\n",
       "      <td>7.822770e+00</td>\n",
       "      <td>7.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>8.116213e+00</td>\n",
       "      <td>7.300913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RMSE train score  RMSE test score\n",
       "RandForest          6.925209e-02         0.051365\n",
       "DecTree             5.872712e-16         0.088696\n",
       "BaggedDecTrees      1.149761e-01         0.102959\n",
       "Adaboost            2.265848e+00         2.251459\n",
       "KNN                 3.395318e+00         4.474329\n",
       "LinReg              7.822770e+00         7.254920\n",
       "SVR                 8.116213e+00         7.300913"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_RMSE=pd.DataFrame([regressors_RMSE_train,regressors_RMSE_test],columns=regressors_name).T\n",
    "reg_RMSE.columns=['RMSE train score','RMSE test score']\n",
    "reg_RMSE.sort_values(by=\"RMSE test score\",ascending=True,inplace=True)\n",
    "reg_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Most regressors have the train and test RMSE on the same order, except single Decision Tree.  \n",
    "The train RMSE is as low as $10^{-16}$ but the test RMSE is only $10^{-2}$.  \n",
    "So, it's clear the single Decision Tree has highly overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'd pick the Random Forest.  \n",
    "Simple because its random selection of features at every split reduces over reliance on any single feature.  \n",
    "This allow the models to generalise well.  \n",
    "In addition, the accuracy score and RMSE agrees that RF is the best too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We could tune several paramters, `max_depth`, `min_samples_split`,`min_samples_leaf` etc.  \n",
    "These affect the complexity of the tree, controlling its overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By common sense, if one has participated in 401k, i.e. `p401k` == 1, then he must have been eligible. `e401k` must be 1 too.  \n",
    "Therefore, although a good predictor, it is meaningless in reality as we're tying to estimate eligibility even before know for sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What is a <i>modelling tactic</i>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df2.drop(columns=['e401k'])\n",
    "y=df2['e401k']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.607871\n",
       "1    0.392129\n",
       "Name: e401k, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()/y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40% are 1, 60% are 0. Still considered balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_class(classifier):\n",
    "    return Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('classifier',classifier)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_name=['LogReg','KNN','DecTree','BaggedDecTrees','RandForest','Adaboost','SVC']\n",
    "classifiers_instance=[LogisticRegression(),KNeighborsClassifier(),DecisionTreeClassifier(),\n",
    "                     BaggingClassifier(),RandomForestClassifier(),AdaBoostClassifier(),SVC()]\n",
    "classifiers_TP=[]\n",
    "classifiers_TN=[]\n",
    "classifiers_FP=[]\n",
    "classifiers_FN=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(classifiers_name)):\n",
    "    pipe=create_pipeline_class(classifiers_instance[i])\n",
    "    pipe.fit(X_train,y_train)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,pipe.predict(X_test)).ravel()\n",
    "    classifiers_TP.append(tp)\n",
    "    classifiers_TN.append(tn)\n",
    "    classifiers_FP.append(fp)\n",
    "    classifiers_FN.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecTree</th>\n",
       "      <td>540</td>\n",
       "      <td>951</td>\n",
       "      <td>188</td>\n",
       "      <td>176</td>\n",
       "      <td>0.741758</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.747922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>509</td>\n",
       "      <td>1098</td>\n",
       "      <td>41</td>\n",
       "      <td>207</td>\n",
       "      <td>0.925455</td>\n",
       "      <td>0.710894</td>\n",
       "      <td>0.804107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggedDecTrees</th>\n",
       "      <td>503</td>\n",
       "      <td>1110</td>\n",
       "      <td>29</td>\n",
       "      <td>213</td>\n",
       "      <td>0.945489</td>\n",
       "      <td>0.702514</td>\n",
       "      <td>0.806090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandForest</th>\n",
       "      <td>500</td>\n",
       "      <td>1120</td>\n",
       "      <td>19</td>\n",
       "      <td>216</td>\n",
       "      <td>0.963391</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.809717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>497</td>\n",
       "      <td>1139</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.694134</td>\n",
       "      <td>0.819456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>497</td>\n",
       "      <td>1138</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.694134</td>\n",
       "      <td>0.818781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>497</td>\n",
       "      <td>1139</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.694134</td>\n",
       "      <td>0.819456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TP    TN   FP   FN  precision    recall        F1\n",
       "DecTree         540   951  188  176   0.741758  0.754190  0.747922\n",
       "KNN             509  1098   41  207   0.925455  0.710894  0.804107\n",
       "BaggedDecTrees  503  1110   29  213   0.945489  0.702514  0.806090\n",
       "RandForest      500  1120   19  216   0.963391  0.698324  0.809717\n",
       "LogReg          497  1139    0  219   1.000000  0.694134  0.819456\n",
       "Adaboost        497  1138    1  219   0.997992  0.694134  0.818781\n",
       "SVC             497  1139    0  219   1.000000  0.694134  0.819456"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_acc_scores=pd.DataFrame([classifiers_TP,classifiers_TN,classifiers_FP,classifiers_FN],\n",
    "                            columns=classifiers_name).T\n",
    "cls_acc_scores.columns=['TP','TN','FP','FN']\n",
    "cls_acc_scores['precision']=cls_acc_scores['TP']/(cls_acc_scores['TP']+cls_acc_scores['FP'])\n",
    "cls_acc_scores['recall']=cls_acc_scores['TP']/(cls_acc_scores['TP']+cls_acc_scores['FN'])\n",
    "cls_acc_scores['F1']=2*(cls_acc_scores['precision']*cls_acc_scores['recall'])/(cls_acc_scores['precision']+cls_acc_scores['recall'])\n",
    "cls_acc_scores.sort_values(by=\"recall\",ascending=False,inplace=True)\n",
    "cls_acc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FP = people who are predicted to be eligible for 401k, but turns out to be not eligible.  \n",
    "FN = people who are predicted not to be eligible, but actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'd rather minimise FN.  \n",
    "It's okay for FP to be high, worst case is they get rejected when they apply.  \n",
    "However, for FN, it's an opportunity cost if these people did not apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We should optimise the recall (also known as sensitivity), as it is targeted as FN being a higher concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "F1 score is the harmonic mean of precision and recall, giving equal weightage to prioritsing FP and FN essentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8283192940232652,\n",
       " 0.8522271076276047,\n",
       " 1.0,\n",
       " 0.9758318739054291,\n",
       " 1.0,\n",
       " 0.8298638911128903,\n",
       " 0.8292585170340682]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_f1_train=[]\n",
    "cls_f1_test=[]\n",
    "for i in range(len(classifiers_name)):\n",
    "    pipe=create_pipeline_class(classifiers_instance[i])\n",
    "    pipe.fit(X_train,y_train)\n",
    "    for j in ['train','test']:\n",
    "        tn, fp, fn, tp = confusion_matrix(globals()[f'y_{j}'],pipe.predict(globals()[f'X_{j}'])).ravel()\n",
    "        precision=tp/(tp+fp)\n",
    "        recall=tp/(tp+fn)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        globals()[f'cls_f1_{j}'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.828319</td>\n",
       "      <td>0.819456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.829259</td>\n",
       "      <td>0.819456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>0.829864</td>\n",
       "      <td>0.818781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggedDecTrees</th>\n",
       "      <td>0.975832</td>\n",
       "      <td>0.807968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.804107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecTree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                F1_train   F1_test\n",
       "LogReg          0.828319  0.819456\n",
       "SVC             0.829259  0.819456\n",
       "Adaboost        0.829864  0.818781\n",
       "RandForest      1.000000  0.809370\n",
       "BaggedDecTrees  0.975832  0.807968\n",
       "KNN             0.852227  0.804107\n",
       "DecTree         1.000000  0.751753"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_f1=pd.DataFrame([cls_f1_train,cls_f1_test],columns=classifiers_name).T\n",
    "cls_f1.columns=['F1_train','F1_test']\n",
    "cls_f1.sort_values(by=\"F1_test\",ascending=False,inplace=True)\n",
    "cls_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Yes, Random Forest, Bagged Decision Trees, and single Decision Trees overfitted badly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'd pick KNN, based on the recall metric (after Single Decision Tree, which really one should never use).  \n",
    "It's still important to reduce FN, hence I choose KNN.  \n",
    "Comparing its F1 train and F1 test, there's a slight overtrain, but not too severe. I'd say it's acceptable to use KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Tune the number of `n_neighbours` in the KNN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
